{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d024dcda-9c34-45d7-9d67-344437b1686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "rcParams['font.size'] = 32  # Set default font size\n",
    "rcParams['axes.titlesize'] = 24\n",
    "rcParams['axes.labelsize'] = 18\n",
    "rcParams['xtick.labelsize'] = 18\n",
    "rcParams['ytick.labelsize'] = 18\n",
    "rcParams['legend.fontsize'] = 18\n",
    "rcParams['figure.titlesize'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8320e84d-5472-4101-ac47-fdb6d1f2fcb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Dirs\n",
      "0        5HfO2_5STO_3_6\n",
      "1  5HfO2_5STO_3_6_pulse\n",
      "choose one directory:1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'MeasResult1_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MeasResult1_time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m df[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(curr_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeasResult1_value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)  \u001b[38;5;66;03m# Vd\u001b[39;00m\n\u001b[0;32m     31\u001b[0m df[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(curr_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeasResult2_value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)  \u001b[38;5;66;03m# Id\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m df[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(\u001b[43mcurr_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMeasResult1_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)   \u001b[38;5;66;03m# Time\u001b[39;00m\n\u001b[0;32m     33\u001b[0m df[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mextend([index] \u001b[38;5;241m*\u001b[39m length)\n\u001b[0;32m     34\u001b[0m device_to_file[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m file\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MeasResult1_time'"
     ]
    }
   ],
   "source": [
    "FILE_PATH = os.path.join('..', 'raw data', '20250930')\n",
    "FIGSIZE = (10, 8)\n",
    "TMP_DIR = \"./tmp\"\n",
    "\n",
    "# Ensure temporary directories exist\n",
    "os.makedirs(TMP_DIR, exist_ok=True)\n",
    "\n",
    "dir_list = list(filter(lambda x: os.path.isdir(os.path.join(FILE_PATH, x)),\n",
    "                       os.listdir(FILE_PATH)))\n",
    "print(pd.DataFrame(dir_list, columns=['Dirs']).head(99))\n",
    "directory = int(input('choose one directory:'))\n",
    "FILE_PATH = os.path.join(FILE_PATH, dir_list[directory])\n",
    "file_list = list(filter(lambda x: '1m_0507_Set_3V8' not in x, os.listdir(FILE_PATH)))\n",
    "file_list.sort(key=lambda x: os.path.getmtime(os.path.join(FILE_PATH, x)))\n",
    "FormingDC_file_list = list(filter(lambda x: 'Forming' in x, file_list))\n",
    "SetDC_file_list = list(filter(lambda x: 'Set' in x, file_list))\n",
    "ResetDC_file_list = list(filter(lambda x: 'Reset' in x, file_list))\n",
    "read_file_list = list(filter(lambda x: 'read' in x, file_list))\n",
    "file_list = list(filter(lambda x: 'Forming' in x or 'Set' in x\n",
    "                        or 'Reset' in x, file_list))\n",
    "FIG_TITLE = FILE_PATH.split('/')[-1].split('(')[0]\n",
    "\n",
    "df = [[], [], [], [], []]\n",
    "device_to_file = {}\n",
    "for index, file in enumerate(file_list, start=1):\n",
    "    try:\n",
    "        curr_df = pd.read_csv(os.path.join(FILE_PATH, file)) if 'csv' in file \\\n",
    "            else pd.read_excel(os.path.join(FILE_PATH, file))\n",
    "        length = curr_df.shape[0]\n",
    "        df[0].extend(curr_df['MeasResult1_value'].values)  # Vd\n",
    "        df[1].extend(curr_df['MeasResult2_value'].values)  # Id\n",
    "        df[2].extend(curr_df['MeasResult1_time'].values)   # Time\n",
    "        df[3].extend([index] * length)\n",
    "        device_to_file[f'{index}'] = file\n",
    "        operation = (['Forming'] if 'Forming' in file\n",
    "                     else ['Set'] if 'Set' in file\n",
    "                     else ['Reset'] if 'Reset' in file else None)\n",
    "        df[4].extend(operation * length)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(file)\n",
    "df = pd.DataFrame(np.transpose(df),\n",
    "                  columns=['Vd (V)', 'Id (A)', 'Time (s)', 'Device', 'Operation'])\n",
    "df['Vd (V)'] = pd.to_numeric(df['Vd (V)'])\n",
    "df['Id (A)'] = pd.to_numeric(df['Id (A)'], errors='coerce')\n",
    "df['Time (s)'] = pd.to_numeric(df['Time (s)'])\n",
    "df['abs(Id)'] = abs(df['Id (A)'])\n",
    "df['Resistance (Ohm)'] = \\\n",
    "    abs(df['Vd (V)'] / df['Id (A)']).where(df['Vd (V)'] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e589a7-b74a-4d09-ae0d-ec9245d9f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FILE_PATH)\n",
    "print(FIG_TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef533ab-27b6-4e1a-9dbc-11a05266c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(FormingDC_file_list) != 0:\n",
    "    forming_df = df[df.Operation == 'Forming']\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=FIGSIZE)\n",
    "    sns.lineplot(data=forming_df, x='Vd (V)', y='Id (A)', estimator=None,\n",
    "                 sort=False)\n",
    "    plt.title(\"Forming(linear)\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=FIGSIZE)\n",
    "    sns.lineplot(data=forming_df, x='Vd (V)', y='Id (A)', estimator=None,\n",
    "                 sort=False)\n",
    "    ax.set(title=\"Forming(log)\", yscale='log')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=FIGSIZE)\n",
    "    sns.lineplot(data=forming_df, x='Vd (V)', y='Id (A)', hue='Device',\n",
    "                 palette='YlGn', estimator=None, sort=False, legend=False, ax=ax)\n",
    "    ax.set(title=\"Forming(log)\", yscale='log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a0cd0-09e1-44e1-ace1-02a78e61a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_file(file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a single file (CSV or Excel) and returns its contents as a DataFrame.\n",
    "    \"\"\"\n",
    "    file_full = os.path.join(FILE_PATH, file)\n",
    "    try:\n",
    "        if \"csv\" in file.lower():\n",
    "            return pd.read_csv(file_full)\n",
    "        else:\n",
    "            return pd.read_excel(file_full)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise\n",
    "\n",
    "\n",
    "def extract_measurement(df: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Extracts measurement values from a DataFrame.\n",
    "    Returns a list containing the absolute values of Id and Vd from the second row.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use .iloc[1] for clarity; you might want to add checks if the DataFrame is empty\n",
    "        return [abs(df['MeasResult1_value'].mean()), abs(df['MeasResult2_value'].mean())]\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(\"Error extracting measurement:\", e)\n",
    "        print(df)\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_file_group(file_list: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process a list of files into a DataFrame containing 'Id' and 'Vd' columns.\n",
    "    Also computes resistance as Vd/Id.\n",
    "    \"\"\"\n",
    "    measurements = []\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            df_file = load_single_file(file)\n",
    "            meas = extract_measurement(df_file)\n",
    "            if meas is not None:\n",
    "                measurements.append(meas)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(file)\n",
    "    if len(measurements) == 0:\n",
    "        df_result = pd.DataFrame(columns=[\"Vd (V)\", \"Id (A)\"])\n",
    "        return df_result\n",
    "    df_result = pd.DataFrame(np.array(measurements), columns=[\"Vd (V)\", \"Id (A)\"])\n",
    "    df_result[\"Resistance (Ohm)\"] = df_result[\"Vd (V)\"] / df_result[\"Id (A)\"]\n",
    "    return df_result\n",
    "\n",
    "\n",
    "def process_read_files_MIM(read_file_list: list) -> list:\n",
    "    \"\"\"\n",
    "    Processes files from a given list for two groups (read1/HRS and read2/LRS).\n",
    "    Returns a list with two DataFrames: [HRS, LRS].\n",
    "    \"\"\"\n",
    "    # Filter files into groups based on naming patterns\n",
    "    read1_files = [f for f in read_file_list if \"read1_1u\" in f]\n",
    "    read2_files = [f for f in read_file_list if \"read2_1u\" in f]\n",
    "    # read3_files = [f for f in read_file_list if \"read2_1u\" in f]\n",
    "    # read4_files = [f for f in read_file_list if \"read2_10u\" in f]\n",
    "\n",
    "    df_read1 = process_file_group(read1_files)\n",
    "    df_read2 = process_file_group(read2_files)\n",
    "    # df_read3 = process_file_group(read3_files)\n",
    "    # df_read4 = process_file_group(read4_files)\n",
    "\n",
    "    # Plot the combined read data\n",
    "    # plot_read_data(df_read1, df_read3.loc[:, 'Vd (V)':'Resistance (Ohm)'])\n",
    "    # plot_read_data(df_read1, df_read4.loc[:, 'Vd (V)':'Resistance (Ohm)'])\n",
    "    # plot_read_data(df_read2, df_read3.loc[:, 'Vd (V)':'Resistance (Ohm)'])\n",
    "    # plot_read_data(df_read2, df_read4.loc[:, 'Vd (V)':'Resistance (Ohm)'])\n",
    "\n",
    "    # return [df_read2, df_read4.loc[:, 'Vd (V)':'Resistance (Ohm)']]\n",
    "\n",
    "    # Plot the combined read data\n",
    "    plot_read_data(df_read1, df_read2)\n",
    "\n",
    "    return [df_read1, df_read2]\n",
    "\n",
    "\n",
    "def plot_read_data(df1: pd.DataFrame, df2: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plots the resistance for the two sets of read data.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "    # title = f\"{FIG_TITLE} Read @Vd={df1.loc[0, 'Vd']}V\"\n",
    "    title = f\"{FIG_TITLE} Read @Vd=0.1V\"\n",
    "    ax.set(title=title, xlabel=\"Cycle\", ylabel=\"Resistance (Ohm)\", yscale=\"log\")\n",
    "    sns.scatterplot(x=df1.index, y=df1[\"Resistance (Ohm)\"], label=\"HRS\", ax=ax, markers=\"o\", s=100)\n",
    "    sns.scatterplot(x=df2.index, y=df2[\"Resistance (Ohm)\"], label=\"LRS\", ax=ax, markers=\"o\", s=100)\n",
    "    ax.tick_params(axis='both', which='major', direction='in', top=True, right=True)\n",
    "    ax.tick_params(axis='both', which='minor', bottom=False, top=False, left=False, right=False)\n",
    "    plt.legend()\n",
    "    output_file = os.path.join(TMP_DIR, f\"{FIG_TITLE}_read_a.png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "read_df = process_read_files_MIM(read_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82dbe51-09c2-4ed5-bf49-621cab810a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_operation(df: pd.DataFrame, operation: str, plot_kwargs: dict = None, save_suffix: str = None):\n",
    "    \"\"\"\n",
    "    Generic function to plot operation data.\n",
    "\n",
    "    Parameters:\n",
    "      df         : DataFrame containing operation data (e.g., 'Set' or 'Reset')\n",
    "      operation  : Operation type, e.g., \"Set\" or \"Reset\"\n",
    "      plot_kwargs: Additional keyword arguments for sns.lineplot\n",
    "      save_suffix: Suffix for the output filename (if not provided, uses operation.lower())\n",
    "    \"\"\"\n",
    "    plot_kwargs = plot_kwargs or {}\n",
    "    save_suffix = save_suffix or operation.lower()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "    title = f\"{FIG_TITLE} {operation} current\"\n",
    "    ax.set(title=title, yscale=\"linear\")\n",
    "\n",
    "    # Choose whether to use hue or not based on kwargs\n",
    "    sns.lineplot(data=df, x=\"Time (s)\", y=\"abs(Id)\", units=\"Device\", estimator=None, sort=False, ax=ax, **plot_kwargs)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', direction='in', top=True, right=True)\n",
    "    ax.tick_params(axis='both', which='minor', bottom=False, top=False, left=False, right=False)\n",
    "    output_file = os.path.join(TMP_DIR, f\"{FIG_TITLE}_{save_suffix}.png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot for Set operation (basic version)\n",
    "set_df = df[df.Operation == \"Set\"]\n",
    "plot_operation(set_df, \"Set\")\n",
    "\n",
    "# Plot for Set operation with ordered hues\n",
    "plot_operation(set_df, \"Set_ordered\",\n",
    "               plot_kwargs={\"hue\": \"Device\", \"palette\": \"YlGn\", \"legend\": False})\n",
    "\n",
    "reset_df = df[df.Operation == \"Reset\"]\n",
    "plot_operation(reset_df, \"Reset\")\n",
    "plot_operation(reset_df, \"Reset_ordered\", plot_kwargs={\"hue\": \"Device\", \"palette\": \"YlGn\", \"legend\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2176f38-57b8-4992-9bad-10f205a18d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_file_len = len(set_df[\"Time (s)\"].unique())\n",
    "set_time_vector = set_df[\"Time (s)\"].iloc[:set_file_len]\n",
    "set_values = set_df[\"abs(Id)\"].values.reshape(-1, set_file_len)\n",
    "for i, set_vector in enumerate(set_values, start=1):\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "    title = f\"{FIG_TITLE} set current ({i})\"\n",
    "    ax.set(title=title, yscale=\"linear\", ylim=(-5e-5, 1.19e-4))\n",
    "\n",
    "    # Choose whether to use hue or not based on kwargs\n",
    "    sns.lineplot(x=set_time_vector, y=set_vector, estimator=None, sort=False, ax=ax)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', direction='in', top=True, right=True)\n",
    "    ax.tick_params(axis='both', which='minor', bottom=False, top=False, left=False, right=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2cd87a-acd6-41da-b9e1-09e99a5c84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_for_origin(read_df: list, set_df: pd.DataFrame, reset_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Exports the provided data frames to an Excel file for Origin.\n",
    "    \"\"\"\n",
    "    readLRS, readHRS = read_df\n",
    "    set_file_len = len(set_df[\"Time (s)\"].unique())\n",
    "    reset_file_len = len(reset_df[\"Time (s)\"].unique())\n",
    "\n",
    "    set_time_vector = set_df[\"Time (s)\"].iloc[:set_file_len]\n",
    "    set_values = np.vstack((set_time_vector, set_df[\"Vd (V)\"].values.reshape(-1, set_file_len)))\n",
    "    set_vd_df = pd.DataFrame(set_values.T, columns=[\"Time (s)\", *[f\"Vd{x}\" for x in range(set_values.shape[0]-1)]])\n",
    "    set_values = np.vstack((set_time_vector, set_df[\"abs(Id)\"].values.reshape(-1, set_file_len)))\n",
    "    set_id_df = pd.DataFrame(set_values.T, columns=[\"Time (s)\", *[f\"Id{x}\" for x in range(set_values.shape[0]-1)]])\n",
    "\n",
    "    reset_time_vector = reset_df[\"Time (s)\"].iloc[:reset_file_len]\n",
    "    reset_values = np.vstack((reset_time_vector, reset_df[\"Vd (V)\"].values.reshape(-1, reset_file_len)))\n",
    "    reset_vd_df = pd.DataFrame(reset_values.T, columns=[\"Time (s)\", *[f\"Vd{x}\" for x in range(reset_values.shape[0]-1)]])\n",
    "    reset_values = np.vstack((reset_time_vector, reset_df[\"abs(Id)\"].values.reshape(-1, reset_file_len)))\n",
    "    reset_id_df = pd.DataFrame(reset_values.T, columns=[\"Time (s)\", *[f\"Id{x}\" for x in range(reset_values.shape[0]-1)]])\n",
    "\n",
    "    # Create a excel file for origin\n",
    "    output_file = os.path.join(FILE_PATH, \"for_origin.xlsx\")\n",
    "    empty_df = pd.DataFrame()\n",
    "    empty_df.to_excel(output_file)\n",
    "    print(\"Exporting to:\", output_file)\n",
    "\n",
    "    with pd.ExcelWriter(output_file, mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "        readLRS.to_excel(writer, sheet_name=\"HRS\", index=False)\n",
    "        readHRS.to_excel(writer, sheet_name=\"LRS\", index=False)\n",
    "        set_vd_df.to_excel(writer, sheet_name=\"Set Vd\", index=False)\n",
    "        set_id_df.to_excel(writer, sheet_name=\"Set Id\", index=False)\n",
    "        reset_vd_df.to_excel(writer, sheet_name=\"Reset Vd\", index=False)\n",
    "        reset_id_df.to_excel(writer, sheet_name=\"Reset Id\", index=False)\n",
    "\n",
    "\n",
    "export_for_origin(read_df, set_df, reset_df)\n",
    "# export_for_origin(read_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fa57a-31b5-49cb-aed9-98efb322b470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
